{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "092f37fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of processed dataset:\n",
      "   age     bmi  children      charges  sex_male  smoker_yes  region_northwest  \\\n",
      "0   19  27.900         0  16884.92400     False        True             False   \n",
      "1   18  33.770         1   1725.55230      True       False             False   \n",
      "2   28  33.000         3   4449.46200      True       False             False   \n",
      "3   33  22.705         0  21984.47061      True       False              True   \n",
      "4   32  28.880         0   3866.85520      True       False              True   \n",
      "\n",
      "   region_southeast  region_southwest  age_smoker  bmi_smoker  age_bmi  \n",
      "0             False              True          19        27.9  530.100  \n",
      "1              True             False           0         0.0  607.860  \n",
      "2              True             False           0         0.0  924.000  \n",
      "3             False             False           0         0.0  749.265  \n",
      "4             False             False           0         0.0  924.160  \n",
      "\n",
      "Dataset shape: (2772, 12)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the processed dataset\n",
    "df = pd.read_csv(\"../data/processed/medical_insurance_processed.csv\")\n",
    "\n",
    "# Display first few rows to confirm it's loaded correctly\n",
    "print(\"First 5 rows of processed dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check the shape of the dataset\n",
    "print(f\"\\nDataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3ef9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shapes:\n",
      "X_train: (2217, 11)\n",
      "y_train: (2217,)\n",
      "\n",
      "Testing set shapes:\n",
      "X_test: (555, 11)\n",
      "y_test: (555,)\n",
      "\n",
      "First 5 rows of X_train:\n",
      "      age    bmi  children  sex_male  smoker_yes  region_northwest  \\\n",
      "1864   21  36.85         0      True       False             False   \n",
      "1997   38  34.80         2     False       False             False   \n",
      "1336   21  25.80         0     False       False             False   \n",
      "655    52  25.30         2     False        True             False   \n",
      "261    20  26.84         1     False        True             False   \n",
      "\n",
      "      region_southeast  region_southwest  age_smoker  bmi_smoker  age_bmi  \n",
      "1864              True             False           0        0.00   773.85  \n",
      "1997             False              True           0        0.00  1322.40  \n",
      "1336             False              True           0        0.00   541.80  \n",
      "655               True             False          52       25.30  1315.60  \n",
      "261               True             False          20       26.84   536.80  \n"
     ]
    }
   ],
   "source": [
    "# --- Data Splitting ---\n",
    "\n",
    "# 1. Define features (X) and target variable (y)\n",
    "# We'll use all columns except 'charges' as features\n",
    "X = df.drop('charges', axis=1)  # All columns except 'charges' (using 'df' which is our loaded data)\n",
    "y = df['charges']               # Only the 'charges' column\n",
    "\n",
    "# 2. Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Display the shapes of the resulting datasets\n",
    "print(\"Training set shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "\n",
    "print(\"\\nTesting set shapes:\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "# 4. Display first few rows of training features to confirm\n",
    "print(\"\\nFirst 5 rows of X_train:\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d8635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model Performance:\n",
      "Mean Squared Error (MSE): 26137763.57\n",
      "Root Mean Squared Error (RMSE): 5112.51\n",
      "Mean Absolute Error (MAE): 2895.21\n",
      "R-squared (R2) Score: 0.8297\n",
      "\n",
      "First 10 Actual vs Predicted Charges:\n",
      "        Actual     Predicted\n",
      "0   8988.15875  10898.135568\n",
      "1  28101.33305  31760.878005\n",
      "2  12032.32600  12280.563740\n",
      "3   1682.59700   2295.525640\n",
      "4   3393.35635   3951.951211\n",
      "5  24106.91255  26423.413894\n",
      "6   4746.34400   6383.683373\n",
      "7  47269.85400  51471.708410\n",
      "8   8556.90700  10277.152633\n",
      "9   2639.04290   3742.176263\n"
     ]
    }
   ],
   "source": [
    "# --- Model Training: Linear Regression ---\n",
    "\n",
    "# 1. Initialize the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# 2. Train the model on the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Make predictions on the testing data\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# 4. Evaluate the model's performance\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# 5. Display the evaluation metrics\n",
    "print(\"Linear Regression Model Performance:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_lr:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_lr:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_lr:.2f}\")\n",
    "print(f\"R-squared (R2) Score: {r2_lr:.4f}\")\n",
    "\n",
    "# 6. Show first 10 actual vs predicted values\n",
    "print(\"\\nFirst 10 Actual vs Predicted Charges:\")\n",
    "comparison_df = pd.DataFrame({'Actual': y_test[:10].values, 'Predicted': y_pred_lr[:10]})\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecb92eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Model Performance:\n",
      "Mean Squared Error (MSE): 7624973.14\n",
      "Root Mean Squared Error (RMSE): 2761.34\n",
      "Mean Absolute Error (MAE): 1325.71\n",
      "R-squared (R2) Score: 0.9503\n",
      "\n",
      "First 10 Actual vs Predicted Charges (Random Forest):\n",
      "        Actual     Predicted\n",
      "0   8988.15875   9597.677216\n",
      "1  28101.33305  27952.079509\n",
      "2  12032.32600  12434.033191\n",
      "3   1682.59700   2024.754422\n",
      "4   3393.35635   4719.297501\n",
      "5  24106.91255  23408.146039\n",
      "6   4746.34400   5278.003712\n",
      "7  47269.85400  47302.240584\n",
      "8   8556.90700  11312.978299\n",
      "9   2639.04290   3119.671920\n"
     ]
    }
   ],
   "source": [
    "# --- Model Training: Random Forest Regressor ---\n",
    "\n",
    "# 1. Initialize the Random Forest Regressor model\n",
    "# We'll use 100 trees (n_estimators) and set a random state for reproducibility\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# 2. Train the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Make predictions on the testing data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# 4. Evaluate the model's performance\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# 5. Display the evaluation metrics\n",
    "print(\"Random Forest Regressor Model Performance:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse_rf:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_rf:.2f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_rf:.2f}\")\n",
    "print(f\"R-squared (R2) Score: {r2_rf:.4f}\")\n",
    "\n",
    "# 6. Show first 10 actual vs predicted values\n",
    "print(\"\\nFirst 10 Actual vs Predicted Charges (Random Forest):\")\n",
    "comparison_df_rf = pd.DataFrame({'Actual': y_test[:10].values, 'Predicted': y_pred_rf[:10]})\n",
    "print(comparison_df_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75bc7633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\absah\\Desktop\\medical-insurance-cost-prediction\\notebooks\n",
      "Project directory: c:\\Users\\absah\\Desktop\\medical-insurance-cost-prediction\n",
      "MLflow Tracking URI set in notebook: file:///c:/Users/absah/Desktop/medical-insurance-cost-prediction/mlruns\n",
      "Using existing experiment: Medical_Insurance_Cost_Prediction with ID: 115075237773415468\n"
     ]
    }
   ],
   "source": [
    "# --- MLflow Integration ---\n",
    "\n",
    "# 1. Import MLflow and os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "\n",
    "# 2. Set the MLflow tracking URI\n",
    "# Explicitly define the path to your main project directory\n",
    "# Adjust this path if your project structure is different\n",
    "# This assumes your notebook is in 'medical-insurance-cost-prediction/notebooks/'\n",
    "# and you want to use 'medical-insurance-cost-prediction/mlruns/'\n",
    "\n",
    "# Get the current working directory (where the notebook is likely run from)\n",
    "# This should be the 'notebooks' directory if run normally from within VS Code\n",
    "current_working_dir = os.getcwd()\n",
    "print(f\"Current working directory: {current_working_dir}\")\n",
    "\n",
    "# Navigate up one level to the main project directory\n",
    "project_dir = os.path.dirname(current_working_dir)\n",
    "print(f\"Project directory: {project_dir}\")\n",
    "\n",
    "# Define the path to the mlruns directory in the main project folder\n",
    "mlruns_path = os.path.join(project_dir, \"mlruns\")\n",
    "tracking_uri = f\"file:///{mlruns_path.replace(os.sep, '/')}\" # Ensure correct URI format\n",
    "\n",
    "# Set the tracking URI for MLflow\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "# 3. Display the tracking URI to confirm\n",
    "print(\"MLflow Tracking URI set in notebook:\", mlflow.get_tracking_uri())\n",
    "\n",
    "# 4. Create an MLflow experiment (if it doesn't exist)\n",
    "experiment_name = \"Medical_Insurance_Cost_Prediction\"\n",
    "try:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    print(f\"Created new experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "except:\n",
    "    # If experiment already exists, get its ID\n",
    "    experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "    if experiment: # Check if experiment was found\n",
    "        experiment_id = experiment.experiment_id\n",
    "        print(f\"Using existing experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "    else:\n",
    "        print(f\"Error: Experiment '{experiment_name}' not found and could not be created.\")\n",
    "        raise # Re-raise the exception if experiment handling fails\n",
    "\n",
    "# --- End MLflow Setup ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "528fb780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/07 13:17:32 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Python 3-12-0\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model logged to MLflow successfully!\n",
      "Run ID: 4b16c04cc334458fb51a0e2f44ee7b04\n"
     ]
    }
   ],
   "source": [
    "# --- Log Random Forest Model to MLflow (Improved) ---\n",
    "\n",
    "# Start an MLflow run specifically for our Random Forest model\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"Random_Forest_Baseline\") as run:\n",
    "    # Log model parameters\n",
    "    mlflow.log_param(\"model_type\", \"RandomForestRegressor\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"random_state\", 42)\n",
    "    \n",
    "    # Log model metrics (using the variables from our previous Random Forest evaluation)\n",
    "    mlflow.log_metric(\"mse\", mse_rf)\n",
    "    mlflow.log_metric(\"rmse\", rmse_rf)\n",
    "    mlflow.log_metric(\"mae\", mae_rf)\n",
    "    mlflow.log_metric(\"r2_score\", r2_rf)\n",
    "    \n",
    "    # Log the trained model itself as an artifact\n",
    "    # Provide an input example to capture the model signature (addresses the warning)\n",
    "    # Using the first 5 rows of X_train as an example\n",
    "    mlflow.sklearn.log_model(sk_model=rf_model, artifact_path=\"model\", input_example=X_train.head())\n",
    "    \n",
    "    # Print confirmation and the Run ID for reference\n",
    "    print(\"Random Forest model logged to MLflow successfully!\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")\n",
    "\n",
    "# Store the Run ID for potential later use (e.g., comparing models)\n",
    "rf_run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a6626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/07 10:05:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "c:\\Python 3-12-0\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model logged to MLflow successfully!\n",
      "Run ID: cb261fcdb1784aa0a30fbbee5c7d63ee\n",
      "\n",
      "--- Model Performance Comparison ---\n",
      "Random Forest (Run ID: 8a781e4b2e4c4d509a765dda2b8c0ee3):\n",
      "  R2 Score: 0.9503\n",
      "  RMSE: $2761.34\n",
      "  MAE: $1325.71\n",
      "\n",
      "Linear Regression (Run ID: cb261fcdb1784aa0a30fbbee5c7d63ee):\n",
      "  R2 Score: 0.8297\n",
      "  RMSE: $5112.51\n",
      "  MAE: $2895.21\n"
     ]
    }
   ],
   "source": [
    "# --- Train and Log Linear Regression Model to MLflow ---\n",
    "\n",
    "# 1. Initialize the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# 2. Train the model on the training data\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# 3. Make predictions on the testing data\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# 4. Evaluate the model's performance\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "# 5. Start an MLflow run specifically for our Linear Regression model\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=\"Linear_Regression_Baseline\") as lr_run:\n",
    "    # Log model parameters (Linear Regression has few hyperparameters, but we'll log the type)\n",
    "    mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "    \n",
    "    # Log model metrics\n",
    "    mlflow.log_metric(\"mse\", mse_lr)\n",
    "    mlflow.log_metric(\"rmse\", rmse_lr)\n",
    "    mlflow.log_metric(\"mae\", mae_lr)\n",
    "    mlflow.log_metric(\"r2_score\", r2_lr)\n",
    "    \n",
    "    # Log the trained model itself as an artifact\n",
    "    # Provide an input example to capture the model signature\n",
    "    mlflow.sklearn.log_model(sk_model=lr_model, artifact_path=\"model\", input_example=X_train.head())\n",
    "    \n",
    "    # Print confirmation and the Run ID for reference\n",
    "    print(\"Linear Regression model logged to MLflow successfully!\")\n",
    "    print(f\"Run ID: {lr_run.info.run_id}\")\n",
    "\n",
    "# Store the Run ID for potential later use\n",
    "lr_run_id = lr_run.info.run_id\n",
    "\n",
    "# 6. Display a summary comparison of both models so far\n",
    "print(\"\\n--- Model Performance Comparison ---\")\n",
    "print(f\"Random Forest (Run ID: {rf_run_id}):\")\n",
    "print(f\"  R2 Score: {r2_rf:.4f}\")\n",
    "print(f\"  RMSE: ${rmse_rf:.2f}\")\n",
    "print(f\"  MAE: ${mae_rf:.2f}\")\n",
    "\n",
    "print(f\"\\nLinear Regression (Run ID: {lr_run_id}):\")\n",
    "print(f\"  R2 Score: {r2_lr:.4f}\")\n",
    "print(f\"  RMSE: ${rmse_lr:.2f}\")\n",
    "print(f\"  MAE: ${mae_lr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "661b21e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'Medical_Insurance_Cost_Predictor'.\n",
      "2025/08/07 10:05:50 WARNING mlflow.tracking._model_registry.fluent: Run with id 8a781e4b2e4c4d509a765dda2b8c0ee3 has no artifacts at artifact path 'model', registering model based on models:/m-98016f48999240f3b87677dfabc4fd16 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered successfully as 'Medical_Insurance_Cost_Predictor' with version 1\n",
      "\n",
      "Registered Model Details:\n",
      "  Name: Medical_Insurance_Cost_Predictor\n",
      "  Version: 1\n",
      "  Creation Timestamp: 1754541350186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'Medical_Insurance_Cost_Predictor'.\n"
     ]
    }
   ],
   "source": [
    "# --- Register the Best Model (Random Forest) in MLflow Model Registry ---\n",
    "\n",
    "# 1. Define a name for our registered model\n",
    "model_name = \"Medical_Insurance_Cost_Predictor\"\n",
    "\n",
    "# 2. Register the Random Forest model from its run\n",
    "# We use the run ID of the Random Forest run to register it\n",
    "registered_model_uri = f\"runs:/{rf_run_id}/model\"\n",
    "\n",
    "try:\n",
    "    # Create the registered model (this will fail if it already exists)\n",
    "    model_details = mlflow.register_model(model_uri=registered_model_uri, name=model_name)\n",
    "    print(f\"Model registered successfully as '{model_name}' with version {model_details.version}\")\n",
    "except mlflow.exceptions.MlflowException as e:\n",
    "    if \"RESOURCE_ALREADY_EXISTS\" in str(e):\n",
    "        # If the model name already exists, create a new version\n",
    "        print(f\"Model '{model_name}' already exists. Creating a new version...\")\n",
    "        model_details = mlflow.register_model(model_uri=registered_model_uri, name=model_name)\n",
    "        print(f\"New version of '{model_name}' registered successfully with version {model_details.version}\")\n",
    "    else:\n",
    "        # If it's a different kind of error, re-raise it\n",
    "        raise e\n",
    "\n",
    "# 3. Confirm the registration by printing details\n",
    "print(f\"\\nRegistered Model Details:\")\n",
    "print(f\"  Name: {model_details.name}\")\n",
    "print(f\"  Version: {model_details.version}\")\n",
    "print(f\"  Creation Timestamp: {model_details.creation_timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce1d860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking registered models...\n",
      "  Model Name: Medical_Insurance_Cost_Predictor, Latest Version: 1\n",
      "  -> Found the target model: Medical_Insurance_Cost_Predictor\n",
      "\n",
      "Model 'Medical_Insurance_Cost_Predictor' is registered.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nif not found:\\n    try:\\n        model_details = mlflow.register_model(\\n            model_uri=f\"runs:/{rf_run_id}/model\",\\n            name=\"Medical_Insurance_Cost_Predictor\"\\n        )\\n        print(f\"\\nModel successfully re-registered as \\'Medical_Insurance_Cost_Predictor\\' with version {model_details.version}\")\\n    except Exception as e:\\n        print(f\"\\nError re-registering model: {e}\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Ensure MLflow is pointing to the correct tracking URI where your experiment/model was saved\n",
    "# This should match what you used before (likely the default local one)\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "\n",
    "# List all registered models to see if yours is there\n",
    "print(\"Checking registered models...\")\n",
    "registered_models = mlflow.search_registered_models()\n",
    "found = False\n",
    "for model in registered_models:\n",
    "    print(f\"  Model Name: {model.name}, Latest Version: {model.latest_versions[0].version}\")\n",
    "    if model.name == \"Medical_Insurance_Cost_Predictor\":\n",
    "        found = True\n",
    "        print(f\"  -> Found the target model: {model.name}\")\n",
    "\n",
    "if found:\n",
    "    print(\"\\nModel 'Medical_Insurance_Cost_Predictor' is registered.\")\n",
    "else:\n",
    "    print(\"\\nModel 'Medical_Insurance_Cost_Predictor' NOT found. Need to register it.\")\n",
    "\n",
    "# If not found, you can re-register it using rf_run_id from earlier in the notebook\n",
    "# Uncomment and run the block below if needed:\n",
    "\"\"\"\n",
    "if not found:\n",
    "    try:\n",
    "        model_details = mlflow.register_model(\n",
    "            model_uri=f\"runs:/{rf_run_id}/model\",\n",
    "            name=\"Medical_Insurance_Cost_Predictor\"\n",
    "        )\n",
    "        print(f\"\\nModel successfully re-registered as 'Medical_Insurance_Cost_Predictor' with version {model_details.version}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError re-registering model: {e}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e88803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking registered models...\n",
      "  Model Name: Medical_Insurance_Cost_Predictor\n",
      "  Latest Version: 1\n",
      "  Run ID associated with this version: 8a781e4b2e4c4d509a765dda2b8c0ee3\n",
      "  Model URI for loading: models:/Medical_Insurance_Cost_Predictor/1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import mlflow\n",
    "\n",
    "# Ensure MLflow points to the correct location (where you saved your experiments)\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "\n",
    "# List registered models and get details\n",
    "print(\"Checking registered models...\")\n",
    "registered_models = mlflow.search_registered_models()\n",
    "target_model_name = \"Medical_Insurance_Cost_Predictor\"\n",
    "found = False\n",
    "for model in registered_models:\n",
    "    if model.name == target_model_name:\n",
    "        found = True\n",
    "        version_info = model.latest_versions[0] # Get info for version 1\n",
    "        print(f\"  Model Name: {model.name}\")\n",
    "        print(f\"  Latest Version: {version_info.version}\")\n",
    "        print(f\"  Run ID associated with this version: {version_info.run_id}\")\n",
    "        print(f\"  Model URI for loading: models:/{model.name}/{version_info.version}\")\n",
    "        break\n",
    "\n",
    "if not found:\n",
    "    print(f\"Model '{target_model_name}' NOT found in the registry.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df8c454b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 8a781e4b2e4c4d509a765dda2b8c0ee3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "156ae918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 8a781e4b2e4c4d509a765dda2b8c0ee3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Run ID: {run.info.run_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
